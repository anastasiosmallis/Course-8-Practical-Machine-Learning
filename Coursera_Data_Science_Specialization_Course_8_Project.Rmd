---
title: "Coursera Data Science Specialization Course 8 Project"
author: "Anastasios Mallis"
date: "January 31, 2016"
output: html_document
---
In this project, our goal is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict whether they performed barbell lifts correctly or incorrectly.

For more information on the data and the goal of its collection please refer to [Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H.](http://groupware.les.inf.puc-rio.br/har#ixzz3ysiRm5VJ)

```{r}
# Downloading the data
train<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",header = TRUE)
test<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", header = TRUE)

# Viewing the different possible outcomes
levels(train$classe)
```
Above we can see the possible different outcomes.

Below is the code in which I will do an initial testing on how well we can predict using the following methods: 
1. Random Forest
2. Generalized Boosted Regression Modeling
3. Linear Discriminant Analysis
4. Least Absolute Shrinkage and Selection Operator

I will exclude from the data, the variables "X" (data point id) and "user_name" as they are unrelated to our analysis. And train on all the remaining variables.

Last but not least I will perform a 2-fold Cross Validation on the training set.

```{r, eval=FALSE}
library(caret)
library(randomForest)
library(gbm)
library(plyr)
library(elasticnet)

# Removing "X" and "user_name"
train<-train[,c(-1,-2)]
test<-test[,c(-1,-2)]

# Cross Validation
fitControl <- trainControl(## 2-fold CV
                           method = "repeatedcv",
                           number = 2,
                           ## repeated ten times
                           repeats = 2)

# 1. Random Forest
# train
fit_rf<- train(classe~., data=train,
                trControl = fitControl,
                method = "rf")
# predict
prf<-predict(fit_rf)
# accuracy calculation
acc_rf<-confusionMatrix(prf,train$classe)$overall['Accuracy']

# 2. Generalized Boosted Regression Modeling
# train
fit_gbm<- train(classe~., data=train,
                trControl = fitControl,
                method = "gbm")
# predict
pgbm<-predict(fit_gbm)
# accuracy calculation
acc_gbm<-confusionMatrix(pgbm,train$classe)$overall['Accuracy']

# 3. Linear Discriminant Analysis
# train
fit_lda<- train(classe~., data=train,
                trControl = fitControl,
                method = "lda")
# predict
plda<-predict(fit_lda)
# accuracy calculation
acc_lda<-confusionMatrix(plda,train$classe)$overall['Accuracy']

# 4. Least Absolute Shrinkage and Selection Operator
# train
fit_lasso<- train(classe~., data=train,
                trControl = fitControl,
                method = "lasso")
# predict
plasso<-predict(fit_lasso)
# accuracy calculation
acc_lasso<-confusionMatrix(plasso,train$classe)$overall['Accuracy']

```
See bellow the out-of-sample accuracy of the four models.
1. Random Forest: `r accrf`.
2. Generalized Boosted Regression Modeling: `r accgbm`.
3. Linear Discriminant Analysis: `r acclda`.
4. Least Absolute Shrinkage and Selection Operator: `r acclasso`.

Now I am going to combine all the methods to find if the combination has better accuracy and if this is they case use that as my predictor.
```{r}

```
The method with the best accuracy is .